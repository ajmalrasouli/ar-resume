module.exports = async function (context, req) {
    // Set CORS headers
    const allowedOrigins = [
        'http://localhost:3000',
        'http://localhost:5173',
        'https://lemon-desert-05dc5301e.6.azurestaticapps.net',
        'https://your-production-domain.azurestaticapps.net'
    ];
    const origin = req.headers.origin;
    
    if (allowedOrigins.includes(origin)) {
        context.res.setHeader('Access-Control-Allow-Origin', origin);
    }
    context.res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');
    context.res.setHeader('Access-Control-Allow-Headers', 'Content-Type');
    
    // Handle preflight requests
    if (req.method === 'OPTIONS') {
        return context.res = { status: 200 };
    }
    
    if (req.method !== 'POST') {
        return context.res = {
            status: 405,
            body: { error: 'Method not allowed' }
        };
    }

    try {
        const { messages, model = 'gpt-3.5-turbo', max_tokens = 500 } = req.body;
        
        if (!messages) {
            return context.res = {
                status: 400,
                body: { error: 'Messages are required' }
            };
        }

        const apiKey = process.env.VITE_OPENAI_API_KEY || process.env.OPENAI_API_KEY;
        if (!apiKey) {
            console.error('OpenAI API key is missing');
            return context.res = {
                status: 500,
                body: { error: 'Server configuration error: Missing API key' }
            };
        }

        console.log('Sending request to OpenAI API...');
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${apiKey}`
            },
            body: JSON.stringify({
                model,
                messages: Array.isArray(messages) ? messages : [{ role: 'user', content: String(messages) }],
                max_tokens: parseInt(max_tokens, 10) || 500,
                temperature: 0.7
            })
        });

        const responseText = await response.text();
        let data;
        
        try {
            data = responseText ? JSON.parse(responseText) : null;
        } catch (e) {
            console.error('Failed to parse API response:', responseText);
            throw new Error('Invalid response from AI service');
        }

        if (!response.ok) {
            console.error('OpenAI API error:', data);
            throw new Error(data?.error?.message || `API request failed with status ${response.status}`);
        }

        if (!data || !data.choices || !Array.isArray(data.choices) || data.choices.length === 0) {
            throw new Error('Invalid response format from AI service');
        }

        context.res = {
            status: 200,
            body: data
        };
    } catch (error) {
        console.error('API Handler Error:', error);
        context.res = {
            status: 500,
            body: {
                error: error.message || 'An error occurred while processing your request'
            }
        };
    }
};
